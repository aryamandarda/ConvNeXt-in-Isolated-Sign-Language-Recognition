# ConvNeXt in Isolated Sign Language Recognition

## Description
This repository contains the necessary code and data to replicate the results of our sign language recognition project using ConvNeXt architecture. The project focuses on recognizing Indian Sign Language and Sign-Language-MNIST datasets while comparing the performances of the ConvNeXt model and the Vision Transformer.

## Repository Structure
- `code.ipynb`: Jupyter notebook containing all the code for the project.
- `Data/`: Directory containing datasets used in this project, including Indian Sign Language and Sign-Language-MNIST.
- `Outputs/`: Contains output images generated by the models.

## Getting Started
To reproduce the results of this research, follow these steps:
1. Clone the repository to your local machine.
2. Run the `code.ipynb` notebook in a Jupyter environment.

## Prerequisites
All information on requirements needed is available in the first few cells of the notebook. Please 'pip install -' whatever libraries are necessary for getting the import cell to work. 

## Acknowledgements
All acknowledgements are cited in the notebook itself. Including the datasets and the code used for their pre-processing.

